{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "du9PiW6NV2TC",
    "outputId": "31d3e541-5dfe-4b3b-f7a3-f6ee007f68a8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.9.2-py3-none-any.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 5.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
      "Collecting huggingface-hub==0.0.12\n",
      "  Downloading huggingface_hub-0.0.12-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Collecting pyyaml>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 46.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.0)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
      "\u001b[K     |████████████████████████████████| 895 kB 57.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.6.4)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.3 MB 35.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 3.13\n",
      "    Uninstalling PyYAML-3.13:\n",
      "      Successfully uninstalled PyYAML-3.13\n",
      "Successfully installed huggingface-hub-0.0.12 pyyaml-5.4.1 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.9.2\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 5.3 MB/s \n",
      "\u001b[?25hInstalling collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.96\n"
     ]
    }
   ],
   "source": [
    "! pip install transformers\n",
    "! pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YFEwCPFQWAFO",
    "outputId": "e19128ff-0e0b-49f4-fe0e-b78574031b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-08-25 18:45:42--  https://dissent.s3-us-west-2.amazonaws.com/data/discourse_EN_FIVE_and_but_because_if_when_2017dec12_test.tsv\n",
      "Resolving dissent.s3-us-west-2.amazonaws.com (dissent.s3-us-west-2.amazonaws.com)... 52.218.244.193\n",
      "Connecting to dissent.s3-us-west-2.amazonaws.com (dissent.s3-us-west-2.amazonaws.com)|52.218.244.193|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 16668907 (16M) [text/tab-separated-values]\n",
      "Saving to: ‘discourse_EN_FIVE_and_but_because_if_when_2017dec12_test.tsv’\n",
      "\n",
      "discourse_EN_FIVE_a 100%[===================>]  15.90M  18.8MB/s    in 0.8s    \n",
      "\n",
      "2021-08-25 18:45:43 (18.8 MB/s) - ‘discourse_EN_FIVE_and_but_because_if_when_2017dec12_test.tsv’ saved [16668907/16668907]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! wget 'https://dissent.s3-us-west-2.amazonaws.com/data/discourse_EN_FIVE_and_but_because_if_when_2017dec12_test.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M-Pu5BOVWDRp"
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5EncoderModel, T5Config, T5Tokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from google.colab import drive\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "enc = LabelEncoder()\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wsHLjd_BWavu"
   },
   "outputs": [],
   "source": [
    "discourse = pd.read_csv('discourse_EN_FIVE_and_but_because_if_when_2017dec12_test.tsv', sep='\\t', header=None)\n",
    "nrows = len(discourse)\n",
    "discourse.columns = ['sent_1', 'sent_2', 'marker']\n",
    "total_sample_size = 80000\n",
    "discourse_small = discourse.groupby('marker', as_index=False).\\\n",
    "    apply(lambda x: x.sample(int((len(x)/nrows)*total_sample_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UX-4zYmVZowF"
   },
   "outputs": [],
   "source": [
    "TRAIN, TEST = train_test_split(discourse_small)\n",
    "TRAIN['part'] = ['tr'] * len(TRAIN)\n",
    "TEST['part'] = ['te'] * len(TEST)\n",
    "df = TRAIN.append(TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Quk8az59WFzm"
   },
   "outputs": [],
   "source": [
    "def load_model(checkpoint):\n",
    "    m = torch.load(f'gdrive/MyDrive/model_{checkpoint}.pth')\n",
    "    model = T5ForConditionalGeneration(T5Config(output_hidden_states=True))\n",
    "    model.load_state_dict(m['model_state_dict'])\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    model.to(device)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xncWMuz-WH8L"
   },
   "outputs": [],
   "source": [
    "def get_emb(df, model, tokenizer):\n",
    "  answers = []\n",
    "  for i in tqdm(df.iterrows()):\n",
    "    sent = i[1][:2].tolist()\n",
    "    with torch.no_grad():\n",
    "      enc = tokenizer(sent, padding=True, \n",
    "                    truncation=True, \n",
    "                    return_attention_mask=True,\n",
    "                    return_tensors='pt')\n",
    "      enc.to(device)\n",
    "      output = model.encoder(**enc)\n",
    "      emb = output.hidden_states\n",
    "      answers.append([torch.mean(e, dim=[0, 1]).cpu().numpy() for e in emb])\n",
    "  return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tRMXkM--WIDb"
   },
   "outputs": [],
   "source": [
    "def classify(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    return (y_pred, accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='micro'),\n",
    "    recall_score(y_test, y_pred, average='micro'), f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w_VQ2W6yWMCc"
   },
   "outputs": [],
   "source": [
    "def probe(epoche, df, scores, pred):\n",
    "    model, tokenizer = load_model(epoche)\n",
    "    print('Model is loaded')\n",
    "    #sent_1 = df.iloc[:,0].apply(lambda x: get_emb(x, model, tokenizer))\n",
    "    #sent_2 = df.iloc[:,1].apply(lambda x: get_emb(x, model, tokenizer))\n",
    "    #X = []\n",
    "    #for i in range(len(sent_1)):\n",
    "    #    emb = sent_1.iloc[i] + sent_2.iloc[i]\n",
    "    #    X.append([e/2 for e in emb])\n",
    "    #df['mean'] = X\n",
    "    TRAIN = df[df['part'] == 'tr']\n",
    "    TEST = df[df['part'] == 'te']\n",
    "    X_train = get_emb(TRAIN, model, tokenizer)\n",
    "    X_test = get_emb(TEST, model, tokenizer)\n",
    "    print('Embeddings are calculated')\n",
    "    enc.fit(df.iloc[:,1])\n",
    "    y = enc.fit(df['marker'])\n",
    "    y_train = enc.transform(TRAIN['marker'])\n",
    "    y_test = enc.transform(TEST['marker'])\n",
    "    for a in tqdm(range(7)):\n",
    "        train = np.array([x[a].tolist() for x in X_train])\n",
    "        test = np.array([x[a].tolist() for x in X_test])\n",
    "        sc = classify(train, test, y_train, y_test)\n",
    "        pred.append(sc[0])\n",
    "        scores.append(sc[1:])\n",
    "    print('Score is calculated')\n",
    "    return scores, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ugOmSXZ9WOP-"
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "scores = []\n",
    "# scores, pred = probe(300000, subjnum, scores, pred)\n",
    "scores, pred = probe(800000, df, scores, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-D9sLBtCWUqb"
   },
   "outputs": [],
   "source": [
    "with open('pred.txt', 'a') as f:\n",
    "  for i in pred:\n",
    "    f.write(','.join(list(map(str, i))))\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZjQrf7v7WWKQ"
   },
   "outputs": [],
   "source": [
    "scores = [[i,] + list(a) for i, a in enumerate(scores)]\n",
    "sc = pd.DataFrame(scores, columns=['layer', 'accuracy', 'precision', 'recall', 'f1-score'])\n",
    "sc.to_csv('scores.csv', mode='a', header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "To-HuumZlJ-0"
   },
   "outputs": [],
   "source": [
    "sc"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "discourse experiment with t5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

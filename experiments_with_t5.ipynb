{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GBbOtKlUVBxe",
    "outputId": "7da47c76-025e-4913-d9bb-e85a2094bfaa"
   },
   "outputs": [],
   "source": [
    "! wget https://raw.githubusercontent.com/facebookresearch/SentEval/master/data/probing/subj_number.txt\n",
    "! wget https://raw.githubusercontent.com/facebookresearch/SentEval/master/data/probing/tree_depth.txt\n",
    "! wget https://raw.githubusercontent.com/facebookresearch/SentEval/master/data/probing/sentence_length.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yLFZYsHAQwh6"
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5EncoderModel, T5Config, T5Tokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "enc = LabelEncoder()\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LMfH3b6We-_S",
    "outputId": "35ea898a-71b1-4e19-f4ed-f4454376e38f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive') #  модели лежат на диске для быстрого доступа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XO4ITLElU-DA"
   },
   "outputs": [],
   "source": [
    "depth = pd.read_csv('tree_depth.txt', sep='\\t', header=None)\n",
    "subjnum = pd.read_csv('subj_number.txt', sep='\\t', header=None)\n",
    "length = pd.read_csv('sentence_length.txt', sep='\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "umdRkQ54Q9pf"
   },
   "outputs": [],
   "source": [
    "def load_model(checkpoint):\n",
    "    m = torch.load(f'/content/gdrive/My Drive/model_{checkpoint} (1).pth')\n",
    "    model = T5ForConditionalGeneration(T5Config(output_hidden_states=True))\n",
    "    model.load_state_dict(m['model_state_dict'])\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "    model.to(device)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_l6LwqIQVeE2"
   },
   "outputs": [],
   "source": [
    "def get_emb(sent, model, tokenizer):\n",
    "  with torch.no_grad():\n",
    "    enc = tokenizer(sent, padding=True, truncation=True, return_tensors='pt')\n",
    "    enc.to(device)\n",
    "    output = model.encoder(\n",
    "      input_ids=enc['input_ids'], \n",
    "      attention_mask=enc[\"attention_mask\"], \n",
    "      return_dict=True\n",
    "    )\n",
    "    # get the final hidden states\n",
    "    emb = output.hidden_states\n",
    "    return [torch.mean(e, 1).squeeze(0).cpu().numpy() for e in emb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ag5fDSPvj-v6"
   },
   "outputs": [],
   "source": [
    "def classify(X_train, X_test, y_train, y_test):\n",
    "    logreg = LogisticRegression()\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    return (y_pred, accuracy_score(y_test, y_pred), precision_score(y_test, y_pred, average='micro'),\n",
    "    recall_score(y_test, y_pred, average='micro'), f1_score(y_test, y_pred, 'micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x6wS3XKd86Id"
   },
   "outputs": [],
   "source": [
    "def probe(epoche, df, scores, pred):\n",
    "    model, tokenizer = load_model(epoche)\n",
    "    print('Model is loaded')\n",
    "    TRAIN = df[df.iloc[:,0] == 'tr']\n",
    "    TEST = df[df.iloc[:,0] == 'te']\n",
    "    X_train = TRAIN.iloc[:,2].apply(lambda x: get_emb(x, model, tokenizer))\n",
    "    X_test = TEST.iloc[:,2].apply(lambda x: get_emb(x, model, tokenizer))\n",
    "    print('Embeddings are calculated')\n",
    "    enc.fit(df.iloc[:,1])\n",
    "    y_train = enc.transform(TRAIN.iloc[:,1])\n",
    "    y_test = enc.transform(TEST.iloc[:,1])\n",
    "    for a in tqdm(range(7)):\n",
    "        train = np.array([x[a].tolist() for x in X_train.to_list()])\n",
    "        test = np.array([x[a].tolist() for x in X_test.to_list()])\n",
    "        sc = classify(train, test, y_train, y_test)\n",
    "        pred.append(sc[0])\n",
    "        scores.append(sc[1:])\n",
    "    print('Score is calculated')\n",
    "    return scores, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369
    },
    "id": "bhvLAKkCWIHE",
    "outputId": "8ac89ec8-348a-45aa-e641-742ffd1f038d"
   },
   "outputs": [],
   "source": [
    "pred = []\n",
    "scores = []\n",
    "# checkpoint = number of checkpoint\n",
    "scores, pred = probe(checkpoint, length, scores, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsN2zwZ76Omi"
   },
   "outputs": [],
   "source": [
    "with open('pred.txt', 'a') as f:\n",
    "      for i in pred:\n",
    "        f.write(','.join(list(map(str, i))))\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RzFh3Qb8mB7i"
   },
   "outputs": [],
   "source": [
    "scores = [[i,] + list(a) for i, a in enumerate(scores)]\n",
    "sc = pd.DataFrame(scores, columns=['layer', 'accuracy', 'precision', 'recall', 'f1-score'])\n",
    "sc.to_csv('new_scores.csv', mode='a', header=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "experiments_with_t5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
